version: '3.8'

services:
  # ========================================
  # NOVA AI FABRIC CORE SERVICES
  # ========================================
  
  nova-ai-fabric:
    build:
      context: ./apps/api
      dockerfile: Dockerfile.ai-fabric
    container_name: nova-ai-fabric
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - NOVA_AI_FABRIC_ENABLED=true
      - NOVA_AI_FABRIC_PORT=3000
      - DATABASE_URL=postgresql://nova_ai_user:${AI_FABRIC_DB_PASSWORD}@postgres-ai:5432/nova_ai_fabric
      - REDIS_URL=redis://redis-ai:6379
      - MONGODB_URL=mongodb://mongo-ai:27017/nova_ai_fabric
      - LOG_LEVEL=info
      - PROMETHEUS_ENABLED=true
    ports:
      - "3000:3000"
    depends_on:
      - postgres-ai
      - redis-ai
      - mongo-ai
    volumes:
      - ./data/ai-models:/workspace/data/ai-models
      - ./data/nova-models:/workspace/data/nova-models
      - ./data/harmony:/workspace/data/harmony
      - ./logs:/workspace/logs
    networks:
      - nova-ai-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/ai-fabric/status"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Nova MCP Server for ChatGPT Integration
  nova-mcp-server:
    build:
      context: ./apps/api
      dockerfile: Dockerfile.mcp
    container_name: nova-mcp-server
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - MCP_SERVER_PORT=3001
      - MCP_SERVER_HOST=0.0.0.0
      - MCP_SERVER_API_KEY=${MCP_SERVER_API_KEY}
      - MCP_SERVER_CORS_ORIGINS=https://chat.openai.com,https://chatgpt.com
      - DATABASE_URL=postgresql://nova_ai_user:${AI_FABRIC_DB_PASSWORD}@postgres-ai:5432/nova_ai_fabric
    ports:
      - "3001:3001"
    depends_on:
      - nova-ai-fabric
      - postgres-ai
    networks:
      - nova-ai-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/.well-known/mcp-server"]
      interval: 30s
      timeout: 10s
      retries: 3

  # GPT-OSS-20B Secure Container
  gpt-oss-secure:
    build:
      context: ./apps/api
      dockerfile: Dockerfile.gpt-oss
    container_name: gpt-oss-secure
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - GPT_OSS_SECURITY_LEVEL=high
      - GPT_OSS_ISOLATION_MODE=container
      - GPT_OSS_ENCRYPTION_ENABLED=true
      - GPT_OSS_MAX_CONCURRENT_REQUESTS=5
      - GPT_OSS_MEMORY_LIMIT=8G
    volumes:
      - ./models/gpt-oss-20b:/workspace/models/gpt-oss-20b:ro
      - gpt-oss-temp:/tmp/gpt-oss
    networks:
      - nova-ai-network
    security_opt:
      - seccomp:runtime/default
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CAP_NET_BIND_SERVICE
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '2.0'
          memory: 4G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 60s
      timeout: 15s
      retries: 3

  # ========================================
  # DATABASE SERVICES
  # ========================================

  # PostgreSQL for AI Fabric data
  postgres-ai:
    image: pgvector/pgvector:pg15
    container_name: postgres-ai
    restart: unless-stopped
    environment:
      - POSTGRES_DB=nova_ai_fabric
      - POSTGRES_USER=nova_ai_user
      - POSTGRES_PASSWORD=${AI_FABRIC_DB_PASSWORD}
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=C --lc-ctype=C
    volumes:
      - postgres-ai-data:/var/lib/postgresql/data
      - ./apps/api/migrations/postgresql:/docker-entrypoint-initdb.d
    ports:
      - "5433:5432"
    networks:
      - nova-ai-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U nova_ai_user -d nova_ai_fabric"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Redis for caching and session management
  redis-ai:
    image: redis:7-alpine
    container_name: redis-ai
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis-ai-data:/data
    ports:
      - "6380:6379"
    networks:
      - nova-ai-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          cpus: '0.1'
          memory: 256M
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # MongoDB for document storage and vector embeddings
  mongo-ai:
    image: mongo:7.0
    container_name: mongo-ai
    restart: unless-stopped
    environment:
      - MONGO_INITDB_ROOT_USERNAME=admin
      - MONGO_INITDB_ROOT_PASSWORD=${MONGO_PASSWORD}
      - MONGO_INITDB_DATABASE=nova_ai_fabric
    volumes:
      - mongo-ai-data:/data/db
      - ./scripts/mongo-init:/docker-entrypoint-initdb.d
    ports:
      - "27018:27017"
    networks:
      - nova-ai-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ========================================
  # VECTOR DATABASE SERVICES
  # ========================================

  # ChromaDB for vector embeddings
  chromadb:
    image: chromadb/chroma:latest
    container_name: chromadb
    restart: unless-stopped
    environment:
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8000
      - CHROMA_SERVER_CORS_ALLOW_ORIGINS=["*"]
    volumes:
      - chromadb-data:/chroma/chroma
    ports:
      - "8000:8000"
    networks:
      - nova-ai-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Qdrant (alternative vector database)
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    restart: unless-stopped
    ports:
      - "6333:6333"
    volumes:
      - qdrant-data:/qdrant/storage
    networks:
      - nova-ai-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ========================================
  # MONITORING & OBSERVABILITY
  # ========================================

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - nova-ai-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana:/etc/grafana/provisioning
    ports:
      - "3002:3000"
    networks:
      - nova-ai-network
    depends_on:
      - prometheus
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          cpus: '0.2'
          memory: 512M

  # Jaeger for distributed tracing
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    restart: unless-stopped
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    ports:
      - "14268:14268"
      - "16686:16686"
    networks:
      - nova-ai-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          cpus: '0.2'
          memory: 512M

  # ElasticSearch for log aggregation
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - nova-ai-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G

  # Kibana for log visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: kibana
    restart: unless-stopped
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    networks:
      - nova-ai-network
    depends_on:
      - elasticsearch
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G

  # ========================================
  # SECURITY & PROXY SERVICES
  # ========================================

  # Nginx reverse proxy with SSL termination
  nginx:
    image: nginx:alpine
    container_name: nova-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
      - nginx-logs:/var/log/nginx
    networks:
      - nova-ai-network
    depends_on:
      - nova-ai-fabric
      - nova-mcp-server
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 256M

  # Vault for secrets management
  vault:
    image: vault:latest
    container_name: vault
    restart: unless-stopped
    cap_add:
      - IPC_LOCK
    environment:
      - VAULT_DEV_ROOT_TOKEN_ID=${VAULT_ROOT_TOKEN}
      - VAULT_DEV_LISTEN_ADDRESS=0.0.0.0:8200
    ports:
      - "8200:8200"
    volumes:
      - vault-data:/vault/data
    networks:
      - nova-ai-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 256M

  # ========================================
  # EXTERNAL MONITORING & ALERTING
  # ========================================

  # Nova Sentinel (Uptime Kuma)
  nova-sentinel:
    image: louislam/uptime-kuma:1
    container_name: nova-sentinel
    restart: unless-stopped
    ports:
      - "3021:3001"
    volumes:
      - ./data/sentinel:/app/data
      - /var/run/docker.sock:/var/run/docker.sock:ro
    environment:
      - NODE_ENV=production
      - UPTIME_KUMA_HOST=0.0.0.0
      - UPTIME_KUMA_PORT=3001
      - UPTIME_KUMA_DISABLE_FRAME_SAMEORIGIN=false
    networks:
      - nova-ai-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001"]
      interval: 30s
      timeout: 10s
      retries: 3

  # GoAlert
  goalert:
    image: goalert/goalert:latest
    container_name: nova-goalert
    restart: unless-stopped
    ports:
      - "8080:8080"
    environment:
      - GOALERT_LISTEN=:8080
      - GOALERT_DB_URL=postgres://nova_goalert_user:${GOALERT_DB_PASSWORD}@postgres-goalert:5432/nova_goalert?sslmode=disable
      - GOALERT_SMTP_FROM=${GOALERT_SMTP_FROM:-alerts@nova.local}
      - GOALERT_SMTP_HOST=${GOALERT_SMTP_HOST:-localhost}
      - GOALERT_SMTP_PORT=${GOALERT_SMTP_PORT:-587}
      - GOALERT_SMTP_USERNAME=${GOALERT_SMTP_USERNAME}
      - GOALERT_SMTP_PASSWORD=${GOALERT_SMTP_PASSWORD}
      - GOALERT_TWILIO_ACCOUNT_SID=${GOALERT_TWILIO_ACCOUNT_SID}
      - GOALERT_TWILIO_AUTH_TOKEN=${GOALERT_TWILIO_AUTH_TOKEN}
      - GOALERT_TWILIO_FROM=${GOALERT_TWILIO_FROM}
      - GOALERT_SLACK_CLIENT_ID=${GOALERT_SLACK_CLIENT_ID}
      - GOALERT_SLACK_CLIENT_SECRET=${GOALERT_SLACK_CLIENT_SECRET}
      - GOALERT_PUBLIC_URL=${GOALERT_PUBLIC_URL:-http://localhost:8080}
      - GOALERT_GITHUB_CLIENT_ID=${GOALERT_GITHUB_CLIENT_ID}
      - GOALERT_GITHUB_CLIENT_SECRET=${GOALERT_GITHUB_CLIENT_SECRET}
      - GOALERT_OIDC_ISSUER=${GOALERT_OIDC_ISSUER}
      - GOALERT_OIDC_CLIENT_ID=${GOALERT_OIDC_CLIENT_ID}
      - GOALERT_OIDC_CLIENT_SECRET=${GOALERT_OIDC_CLIENT_SECRET}
    volumes:
      - ./data/goalert:/data
    networks:
      - nova-ai-network
    depends_on:
      - postgres-goalert
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # GoAlert Database
  postgres-goalert:
    image: postgres:16-alpine
    container_name: postgres-goalert
    restart: unless-stopped
    environment:
      - POSTGRES_DB=nova_goalert
      - POSTGRES_USER=nova_goalert_user
      - POSTGRES_PASSWORD=${GOALERT_DB_PASSWORD}
      - POSTGRES_INITDB_ARGS=--auth-host=scram-sha-256
    volumes:
      - postgres-goalert-data:/var/lib/postgresql/data
      - ./data/goalert/init:/docker-entrypoint-initdb.d
    networks:
      - nova-ai-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U nova_goalert_user -d nova_goalert"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ========================================
  # BACKUP & MAINTENANCE SERVICES
  # ========================================

  # Automated backup service
  backup-service:
    build:
      context: ./scripts/backup
      dockerfile: Dockerfile
    container_name: backup-service
    restart: unless-stopped
    environment:
      - BACKUP_SCHEDULE=0 2 * * *
      - BACKUP_RETENTION_DAYS=30
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - S3_BUCKET=${BACKUP_S3_BUCKET}
    volumes:
      - postgres-ai-data:/backup/postgres:ro
      - mongo-ai-data:/backup/mongo:ro
      - redis-ai-data:/backup/redis:ro
      - ./data:/backup/data:ro
    networks:
      - nova-ai-network
    depends_on:
      - postgres-ai
      - mongo-ai
      - redis-ai
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          cpus: '0.1'
          memory: 256M

# ========================================
# VOLUMES
# ========================================
volumes:
  postgres-ai-data:
    driver: local
  postgres-goalert-data:
    driver: local
  redis-ai-data:
    driver: local
  mongo-ai-data:
    driver: local
  chromadb-data:
    driver: local
  qdrant-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  elasticsearch-data:
    driver: local
  vault-data:
    driver: local
  nginx-logs:
    driver: local
  gpt-oss-temp:
    driver: local
    driver_opts:
      type: tmpfs
      device: tmpfs

# ========================================
# NETWORKS
# ========================================
networks:
  nova-ai-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# ========================================
# PRODUCTION DEPLOYMENT CONFIGS
# ========================================

# For Kubernetes deployment, use the following configurations:

# Horizontal Pod Autoscaler (HPA) example:
# apiVersion: autoscaling/v2
# kind: HorizontalPodAutoscaler
# metadata:
#   name: nova-ai-fabric-hpa
# spec:
#   scaleTargetRef:
#     apiVersion: apps/v1
#     kind: Deployment
#     name: nova-ai-fabric
#   minReplicas: 2
#   maxReplicas: 10
#   metrics:
#   - type: Resource
#     resource:
#       name: cpu
#       target:
#         type: Utilization
#         averageUtilization: 70
#   - type: Resource
#     resource:
#       name: memory
#       target:
#         type: Utilization
#         averageUtilization: 80

# Deployment with rolling update strategy:
# apiVersion: apps/v1
# kind: Deployment
# metadata:
#   name: nova-ai-fabric
# spec:
#   replicas: 3
#   strategy:
#     type: RollingUpdate
#     rollingUpdate:
#       maxSurge: 1
#       maxUnavailable: 0
#   selector:
#     matchLabels:
#       app: nova-ai-fabric
#   template:
#     metadata:
#       labels:
#         app: nova-ai-fabric
#     spec:
#       containers:
#       - name: nova-ai-fabric
#         image: nova/ai-fabric:latest
#         ports:
#         - containerPort: 3000
#         resources:
#           requests:
#             memory: "2Gi"
#             cpu: "1"
#           limits:
#             memory: "4Gi"
#             cpu: "2"
#         livenessProbe:
#           httpGet:
#             path: /api/ai-fabric/status
#             port: 3000
#           initialDelaySeconds: 30
#           periodSeconds: 10
#         readinessProbe:
#           httpGet:
#             path: /api/ai-fabric/health
#             port: 3000
#           initialDelaySeconds: 5
#           periodSeconds: 5
